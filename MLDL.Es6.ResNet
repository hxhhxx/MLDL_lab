{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO56njAcRZ5OpgbQS3OrOLR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Lab6:Ex1.2=(Lab1:Ex4:write a dataset class)"],"metadata":{"id":"sNpZjgH2PLev"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"DXjbKTr4EvJN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680961365430,"user_tz":-120,"elapsed":9220,"user":{"displayName":"xiao huan","userId":"13717666453857622861"}},"outputId":"19acdd1d-55e8-4b9c-a035-b6594f5b0b27"},"outputs":[{"output_type":"stream","name":"stdout","text":["/root\n","--2023-04-08 13:42:36--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 170498071 (163M) [application/x-gzip]\n","Saving to: ‘cifar-10-python.tar.gz’\n","\n","cifar-10-python.tar 100%[===================>] 162.60M  47.2MB/s    in 3.9s    \n","\n","2023-04-08 13:42:40 (42.1 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n","\n"]}],"source":["# download the CIFAR-10 dataset and untar it\n","%cd\n","!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","!tar -xf cifar-10-python.tar.gz"]},{"cell_type":"code","source":["# function to load pickled data from the dataset\n","def unpickle(data_file):\n","    import pickle\n","    with open(data_file, 'rb') as fo:\n","        data = pickle.load(fo, encoding='latin1')\n","    return data"],"metadata":{"id":"WnU3ZytdHgxI","executionInfo":{"status":"ok","timestamp":1680961576890,"user_tz":-120,"elapsed":760,"user":{"displayName":"xiao huan","userId":"13717666453857622861"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# read the first batch file and metadata\n","file_1 = 'cifar-10-batches-py/data_batch_1'\n","meta_file = 'cifar-10-batches-py/batches.meta'\n","\n","data_1 = unpickle(file_1)\n","meta = unpickle(meta_file)"],"metadata":{"id":"1-qZM3ukLu0F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# meta data files contains label names\n","meta['label_names']"],"metadata":{"id":"t5hRqEsQLyVH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# discover that each batch file is a dictionary, with the following keys\n","type(data_1), list(data_1.keys())\n","# discover that the 'data' field contains a numpy array with the images\n","type(data_1['data']), data_1['data'].shape"],"metadata":{"id":"rJo0hL0XL1Rw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# each array in the matrix is a 32x32 flattened image\n","3072 / 32 /32 /3"],"metadata":{"id":"AumRHmBwMAuA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","import pickle\n","import numpy as np\n","import os\n","\n","def unpickle(data_file):\n","    import pickle\n","    with open(data_file, 'rb') as fo:\n","        data = pickle.load(fo, encoding='latin1')\n","    return data\n","    \n","class Cifar10(Dataset):\n","    def __init__(self, dataset_folder, split='train', transform=None):\n","        assert split in ['train', 'test'], 'split must be either train or test'\n","        \n","        # read paths of batch files and metadata\n","        if split == 'train':\n","            batch_files = [file_path for file_path in os.listdir(dataset_folder) if file_path.startswith('data_batch')]\n","        else:\n","            batch_files = ['test_batch']\n","\n","        images = []\n","        labels = []\n","        # load images and the labels from the batch files into a list\n","        for batch in batch_files:\n","            data = unpickle(os.path.join(dataset_folder, batch))\n","            batch_images = data['data']\n","            batch_images = batch_images.reshape(len(batch_images),3,32,32)\n","            batch_labels = data['labels']\n","\n","            images.append(batch_images)\n","            labels += batch_labels\n","\n","        # stack the images into a single array\n","        self.images = np.stack(images).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n","        self.labels = labels\n","        self.meta = unpickle(os.path.join(dataset_folder, 'batches.meta'))['label_names']\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, index):\n","        image = self.images[index]\n","        label = self.labels[index]\n","\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        return image, label"],"metadata":{"id":"wBF1gyh0MY-U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchvision.transforms as T\n","\n","dataset_folder = 'cifar-10-batches-py'\n","transform = T.ToTensor()\n","transform = T.Compose([\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# instantiate the Dataset class\n","train_ds = Cifar10(dataset_folder, transform=transform)"],"metadata":{"id":"vPNYAaTaPr-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","batch_size = 4\n","################ USE OUR DATASETS #################################\n","trainset = train_ds                                          shuffle=True, num_workers=2) \n","\n","testset = test_ds"],"metadata":{"id":"MxMQSEXURcNQ"},"execution_count":null,"outputs":[]}]}